\chapter{Cluster Analysys}
\label{ch:cluster}

    In questo capitolo si descriveranno le attività svolte per realizzare dei \textit{clustering} sulle versioni ad attributi continui dei data set prodotti nella fase di \textit{preprocessing} (descritta nel Capitolo \ref{ch:prepr}).

\section{Introduzione alla Cluster Analysys}

    Volendo spendere poche parole per delineare un quadro generale e impiegando una massiccia astrazione dai dettagli, possiamo descrivere un \textit{clustering} come segue, citando direttamente da \cite{clustering}:\\

    "Il \textbf{clustering} o \textbf{analisi dei gruppi} (dal termine inglese \textit{cluster analysis} introdotto da Robert Tryon nel 1939) è un insieme di tecniche di analisi multivariata dei dati volte alla selezione e raggruppamento di elementi omogenei in un insieme di dati."\\

    Volendo sintetizzare ulteriormente questi concetti, si può dire che un \textit{clustering} su di un certo data set è un raggruppamento di istanze \textbf{simili fra loro}. Citando sempre da \cite{clustering}:\\

    "Le tecniche di clustering si basano su misure relative alla somiglianza tra gli elementi. In molti approcci questa similarità, o meglio, dissimilarità, è concepita in termini di distanza in uno spazio multidimensionale. La bontà delle analisi ottenute dagli algoritmi di clustering dipende molto dalla scelta della metrica, e quindi da come è calcolata la distanza. Gli algoritmi di clustering raggruppano gli elementi sulla base della loro distanza reciproca, e quindi l'appartenenza o meno ad un insieme dipende da quanto l'elemento preso in esame è distante dall'insieme stesso."\\

    Questa breve ma efficace descrizione sommaria fornisce già una sufficiente infarinatura riguardo al tipo di azioni da compiere per ottenere un \textit{clustering}: si tratta infatti di cercare all'interno dei data set in esame dei gruppi di istanze simili fra di loro per qualche criterio --- che vedremo essere delle metriche di distanza in uno spazio multidimensionale definito dagli attributi dei dati.\\

    Quanto scritto può essere sufficiente per delineare il quadro generale nel quale si è operato per compiere i passi descritti successivamente. Ovviamente, una trattazione esaustiva sull'argomento necessiterebbe ben altro spazio di quello che si può dedicare in questa tesi di laurea, perciò si rimanda alla consultazione di \cite{dispense} per ulteriori dettagli, qualora quanto sopra riportato non dovesse essere sufficiente per la comprensione di quanto seguirà.

\section{Algoritmi di Clustering}

    La realizzazione di un \textit{clustering} su dei \textit{big data} è ovviamente una di quelle attività che hanno bisogno di essere delegate a un algoritmo per essere eseguite. Si descriveranno in questa sezione alcuni dei più efficaci algoritmi di \textit{clustering} e le implementazioni di Weka.

    \subsection{Algoritmo K-Means}

        Uno dei più noti algoritmi di \textit{clustering} che consente di imporre a priori il numero di \textit{cluster} cercati è senza dubbio \textbf{K-Means}. Come si può leggere in \cite{dispense}:\\

        "The K-means clustering technique is simple [...]. We first choose \textit{K} initial centroids, where \textit{K} is a user-specified parameter, namely, the number of clusters desired. Each point is then assigned to the closest centroid, and each collection of points assigned to a centroid is a cluster. The centroid of each cluster is then updated based on the points assigned to the cluster. We repeat the assignment and update steps until no point changes clusters, or equivalently, until the centroids remain the same." \\

        Il che significa, traducendo e parafrasando:\\

        "La tecnica K-Means è semplice: scegliamo inizialmente \textit{K} centroidi iniziali, dove \textit{K} è il numero di cluster desiderati. Ogni punto del data set è assegnato al centroide più vicino, e ogni collezione di punti assegnati a un centrode è un cluster. Il centroide di ogni cluster viene poi ricalcolato, basandosi sui punti che gli sono stati assegnati. Si ripetono questi passi fino a che nessun punto cambia cluster, o i centroidi non cambiano."\\

        Quindi, si tratta di una procedura iterativa che, a partire da un numero fissato di punti iniziali, chiamati centroidi, migliora ad ogni passo gli assegnamenti fino a che non si raggiunge una situazione di stabilità. \\

        Le librerie di Weka mettono a disposizione una implementazione di K-Means, che offre di poter configurare un gran numero di parametri (come si può vedere in Figura \ref{kmeans_weka}).

        \begin{figure}
            \centering
            \caption{finestra che mostra i parametri impostabili dell'algoritmo K-Means}
            \label{kmeans_weka}
            \includegraphics[scale=0.80]{img/cluster_k_means.png}
        \end{figure}

    \subsection{Algoritmo DBSCAN}

        Una algoritmo sostanzialmente diverso dal precedente è DBSCAN, che non si basa sul minimizzare le distanze dal centroide del \textit{cluster}, ma bensì sul raggruppare le istanze del data set in base alla loro \textbf{densità}. \\

        Una informale ma potente descrizione di questo si può leggere in \cite{dispense}:

        "Density-based clustering locates regions of high density that are separated from one another by regions of low density. DBSCAN is a simple and effective density-based clustering algorithm [...]"\\

        Che tradotto significa:\\

        "Le teniche di clustering basate sulla densità individuano regioni dense separate le une dalle altre da regioni meno dense. DBSCAN è un algoritmo di clustering basato sulla densità semplice ed efficace."\\

        Quindi, si può dire che DBSCAN sia un algoritmo che, a differenza di K-Means, non cerca di individuare a quale dei cluster decisi inizialmente appartenga una data istanza, ma individua invece i cluster "naturali" del data set basandosi sulal densità di istanze nelle varie regioni dello spazio multidimensionali definito dagli attributi. \\

        L'implementazione di DBSCAN fornita da Weka, come si può vedere in Figura \ref{dbscan_weka}, è molto basilare, ma totalmente funzionale.

        \begin{figure}
            \centering
            \caption{finestra che mostra i parametri impostabili dell'algoritmo DBSCAN}
            \label{dbscan_weka}
            \includegraphics[scale=0.55]{img/dbscan_weka.png}
        \end{figure}

\section{Clustering sulle Valutazioni dei Corsi}

    Una prima serie di tentativi di \textit{cluster analysis} è stata fatta sul data set condensato delle valutazioni dei corsi, utilizzando l'algoritmo K-Means.

    \subsection{Lancio di K-Means}

        Adottando un metodo empirico di \textit{trial-and-error}, sono state effettuati innumerevoli lanci di K-Means variando di volta in volta i parametri di input. \\

        Quella che segue è la configurazione che genera il miglior risultato ottenuto:

        \begin{center}
            \texttt{weka.clusterers.SimpleKMeans -init 0 -max-candidates 100 -periodic-pruning 10000 -min-density 2.0 -t1 -1.25 -t2 -1.0 -V -M -N 2 -A "weka.core.EuclideanDistance -R first-last" -I 5000 -num-slots 1 -S 997}
        \end{center}

        Nonostante l'elevato numero di parametri a disposizione, in realtà soltanto alcuni hanno influenzato il risultato finale:

        \begin{itemize}
            \item come metrica è stata scelta la \textbf{distanza Euclidea}\footnote{Si tratta di una metrica che misurala distanza fra due punti di uno spazio multidimensionale come la lunghezza del segmento che li unisce.};
            \item sono stati imposti due centroidi iniziali scelti casualmente, ottenendo pertanto un partizionamento con due cluster
        \end{itemize}

        Ai fini del clustering, sono stati considerati soltanto tre attributi: la valutazione complessiva del corso, la deviazione standard delle valutazioni e la percentuali di valutazioni sufficienti.

        \lstinputlisting[caption={Output della console di Weka relativo al lancio di K-Means sul data set delle valutazioni dei corsi}]{../cluster/eval_kmeans.txt}

        \begin{figure}
            \centering
            \caption{sezione dello spazio di esistenza del data set delle valutazione dei corsi lungo il piano definito da "valutazione complessiva" e "percentuale di valutazioni sufficienti", con evidenziato per ogni istanza il cluster di appartenenza}
            \label{eval_kmeans}
            \includegraphics[scale=1.2]{../cluster/eval_kmeans.png}
        \end{figure}

        Come si può vedere dalla Figura \ref{eval_kmeans}, il data set è stato diviso in due cluster che appaiono visivamente ben separati.

        \begin{itemize}
            \item \textbf{Cluster 1} (rosso): A. A. 2013-2014 e 2010-2011
            \item \textbf{Cluster 0} (blu): gli altri cinque A. A.
        \end{itemize}

    \subsection{Tentativo di utilizzo di DBSCAN}

\section{Clustering sulla join dei due data set}

    \subsection{Lancio di K-Means}

    \subsection{Analisi dei risultati di K-Means}